{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f4c1b6",
   "metadata": {},
   "source": [
    "Exploratory data analysis is *exploratory* by nature, often used to get a sense of the content and structure of a dataset before diving into specific research questions.  For this homework, you have one task: tell us something interesting about a dataset using topic modeling. You are free to use any dataset (even those from Kaggle this time), but see sample datasets below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9dd854",
   "metadata": {},
   "source": [
    "* [CMU Book Summary Dataset](https://www.cs.cmu.edu/~dbamman/booksummaries.html)\n",
    "    * Metadata: Title, author, publication date, genre\n",
    "\n",
    "* [CMU Movie Summary Dataset](http://www.cs.cmu.edu/~ark/personas/)\n",
    "    * Metadata: Movie box office revenue, genre, release date, runtime, and language\n",
    "\n",
    "* [Large Movie Review Dataset](https://ai.stanford.edu/~amaas/data/sentiment/)\n",
    "    * Metadata: positive/negative sentiment\n",
    "    \n",
    "* [Congressional Speech Data](https://www.cs.cornell.edu/home/llee/data/convote.html)\n",
    "    * Metadata: political party\n",
    "    \n",
    "* [100K ArXiv abstracts](https://drive.google.com/file/d/1ThK1D9AstYI6s2Z7m9SmvLqLZPneMp12/view?usp=sharing)\n",
    "    * Metadata: ArXiv subject (e.g., math, physics, cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc7969a",
   "metadata": {},
   "source": [
    "For any dataset, you'll have to understand the format in order to read in the textual part (and any metadata of interest); and then tokenize the text before passing it on to topic modeling.\n",
    "\n",
    "Refer to `4.eda/TopicModel.ipynb` for example code on how to work with topic models in gensim, and remember that we've considered several concepts already for characterizing differences across groups; feel free to draw on those as you see appropriate for this exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c4a717",
   "metadata": {},
   "source": [
    "A **check** submission will run topic modeling on the text of your chosen dataset and discuss the topics that emerge; a **check-plus** submission will relate variation in those topics to aspects of metadata (e.g., discussing interesting topical differences over time or between genre/political party, etc.).  In all cases, be sure to explain why what you have found is interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c7da541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\linzh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# CMU Book Summary Dataset\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import operator\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c84fe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stopwords(filename):\n",
    "    stopwords={}\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            stopwords[line.rstrip()]=1\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a66be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = {k:1 for k in stopwords.words('english')}\n",
    "stop_words.update(read_stopwords(\"../data/jockers.stopwords\"))\n",
    "stop_words[\"'s\"]=1\n",
    "stop_words=list(stop_words.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c2da9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(word, stopwords):\n",
    "    \n",
    "    \"\"\" Function to exclude words from a text \"\"\"\n",
    "    \n",
    "    # no stopwords\n",
    "    if word in stopwords:\n",
    "        return False\n",
    "    \n",
    "    # has to contain at least one letter\n",
    "    if re.search(\"[A-Za-z]\", word) is not None:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e393ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata: Title, author, publication date, genre\n",
    "\n",
    "def read_docs(metadataFile, stopwords):\n",
    "    \n",
    "    idds = []\n",
    "    titles = []\n",
    "    authors = []\n",
    "    p_dates = []\n",
    "    # genres = []\n",
    "\n",
    "    docs=[]\n",
    "\n",
    "    with open(metadataFile, encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "\n",
    "            cols=line.rstrip().split(\"\\t\")\n",
    "\n",
    "            idd    = cols[0]\n",
    "            title  = cols[2]\n",
    "            author = cols[3]\n",
    "            p_date = cols[4]\n",
    "            # genre  = cols[5]\n",
    "\n",
    "            if len(idd) != 0 and len(title) != 0 and len(author) != 0 and len(p_date) != 0:\n",
    "                idds.append(idd)\n",
    "                titles.append(title)\n",
    "                authors.append(author)\n",
    "                p_dates.append(p_date)\n",
    "\n",
    "                tokens=nltk.word_tokenize(cols[6].lower())\n",
    "                tokens=[x for x in tokens if filter(x, stopwords)]\n",
    "                docs.append(tokens)\n",
    "                \n",
    "    return docs, titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3e992da",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadataFile=\"../data/booksummaries.txt\"\n",
    "data, doc_names=read_docs(metadataFile, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fabac94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, doc_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd9492a",
   "metadata": {},
   "source": [
    "Using gensim's corpora.dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fea411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocab from data; restrict vocab to only the top 10K terms that show up in at least 5 documents \n",
    "# and no more than 50% of all documents\n",
    "\n",
    "dictionary = corpora.Dictionary(data)\n",
    "dictionary.filter_extremes(no_below=5, no_above=.5, keep_n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86a3e197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace dataset with numeric ids words in vocab (and exclude all other words)\n",
    "corpus = [dictionary.doc2bow(text) for text in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92a8c952",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9e70edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=num_topics, \n",
    "                                           passes=10,\n",
    "                                           alpha='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8061903c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0:\tmagic world find help dragon power kill magical dark human\n",
      "topic 1:\tfind tells island away water people camp day river city\n",
      "topic 2:\tarmy battle men death father lord help escape brother killed\n",
      "topic 3:\tearth planet time human space world humans system alien years\n",
      "topic 4:\tpark fox monk ms. tarzan beast cult badger lion mole\n",
      "topic 5:\tnovel murder death story police killer case woman investigation murdered\n",
      "topic 6:\theaven cat circus cats cal tintin drake odd smiley gregor\n",
      "topic 7:\tde sir england french la london english british spain spanish\n",
      "topic 8:\tschool mother n't time father friends finds tells day goes\n",
      "topic 9:\tmr. mrs. children boy fly story game mouse book flock\n",
      "topic 10:\tcase company firm bridge drug number smith henri mexico bank\n",
      "topic 11:\twar family novel american white world father black women story\n",
      "topic 12:\tnarrator abbot day boy father sherlock hermit priest horse brother\n",
      "topic 13:\tfamily father mother life wife daughter years husband brother time\n",
      "topic 14:\tbook novel story world characters life character society describes author\n",
      "topic 15:\thouse tells find police room killed kill goes finds body\n",
      "topic 16:\tstark ndash adams chancellor briar wall archer foundation animal darkness\n",
      "topic 17:\tworld god empire power time order fallen people priest end\n",
      "topic 18:\twar general states army president united government forces military attack\n",
      "topic 19:\tship crew captain mission aboard escape team island agent bond\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_topics):\n",
    "    print(\"topic %s:\\t%s\" % (i, ' '.join([term for term, freq in lda_model.show_topic(i, topn=10)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22dcb5be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "magic world find help dragon power kill magical dark human\n",
      "\n",
      "0\t0.960\tCavern of the Fear\n",
      "0\t0.911\tMagic Moon\n",
      "0\t0.908\tDarke\n",
      "0\t0.896\tTrail of the Wolf\n",
      "0\t0.889\tCube Route\n",
      "\n",
      "find tells island away water people camp day river city\n",
      "\n",
      "1\t0.890\tThe Moomins and the Great Flood\n",
      "1\t0.888\tThe Fourth Apprentice\n",
      "1\t0.885\tHarimau! Harimau!\n",
      "1\t0.848\tThe Secret of the Forgotten City\n",
      "1\t0.841\tThe Borrowers Afloat\n",
      "\n",
      "army battle men death father lord help escape brother killed\n",
      "\n",
      "2\t0.872\tViking Warrior\n",
      "2\t0.863\tDurgeshnandini\n",
      "2\t0.822\tCaptain from Castile\n",
      "2\t0.804\tDurandal\n",
      "2\t0.801\tKapalkundala\n",
      "\n",
      "earth planet time human space world humans system alien years\n",
      "\n",
      "3\t0.889\tAbduction\n",
      "3\t0.882\tThe Flaming Arrow\n",
      "3\t0.864\tThe World at the End of Time\n",
      "3\t0.852\tManifold: Space\n",
      "3\t0.834\tThe Abode of Life\n",
      "\n",
      "park fox monk ms. tarzan beast cult badger lion mole\n",
      "\n",
      "4\t0.506\tTarzan Triumphant\n",
      "4\t0.350\tFox's Feud\n",
      "4\t0.348\tTarzan and the Lost Empire\n",
      "4\t0.331\tTarzan the Magnificent\n",
      "4\t0.319\tIn the Path of the Storm\n",
      "\n",
      "novel murder death story police killer case woman investigation murdered\n",
      "\n",
      "5\t0.931\tThe Cutting Room\n",
      "5\t0.892\tExit Wounds\n",
      "5\t0.873\tThe Veiled One\n",
      "5\t0.870\tBefore I Go to Sleep\n",
      "5\t0.827\tThe Lover's Dictionary\n",
      "\n",
      "heaven cat circus cats cal tintin drake odd smiley gregor\n",
      "\n",
      "6\t0.866\tBlack Heart of Jamaica\n",
      "6\t0.609\tDen of Thieves\n",
      "6\t0.590\tSuccubus Revealed\n",
      "6\t0.569\tSeesaw\n",
      "6\t0.367\tIngenious Pain\n",
      "\n",
      "de sir england french la london english british spain spanish\n",
      "\n",
      "7\t0.771\tA Manhã do Mundo\n",
      "7\t0.528\tRun for Your Life\n",
      "7\t0.504\tA Conspiracy of Friends\n",
      "7\t0.494\tSharpe's Devil\n",
      "7\t0.462\tSharpe's Escape\n",
      "\n",
      "school mother n't time father friends finds tells day goes\n",
      "\n",
      "8\t0.989\tYou Don't Know Me\n",
      "8\t0.983\tCloud Busting\n",
      "8\t0.982\tP.S. Longer Letter Later\n",
      "8\t0.972\tReport to the Principal's Office\n",
      "8\t0.972\tOn Pointe\n",
      "\n",
      "mr. mrs. children boy fly story game mouse book flock\n",
      "\n",
      "9\t0.894\tWhen the Moon Forgot\n",
      "9\t0.748\tThe Summer Birds\n",
      "9\t0.684\tThe Demigod Diaries\n",
      "9\t0.650\tDry-Fly Fishing in Theory and Practice\n",
      "9\t0.614\tThe Very Bad Book\n",
      "\n",
      "case company firm bridge drug number smith henri mexico bank\n",
      "\n",
      "10\t0.713\tThe Litigators\n",
      "10\t0.655\tUnited!\n",
      "10\t0.528\tOutlaw\n",
      "10\t0.505\tTexas Fever\n",
      "10\t0.499\tLean Mean Thirteen\n",
      "\n",
      "war family novel american white world father black women story\n",
      "\n",
      "11\t0.837\tRaboliot\n",
      "11\t0.783\tThe Last Letter Home\n",
      "11\t0.776\tThe Sweetheart of the Templar From the Valley of Rephaim\n",
      "11\t0.772\tAlways Hiding\n",
      "11\t0.750\tThe Emperor's Children\n",
      "\n",
      "narrator abbot day boy father sherlock hermit priest horse brother\n",
      "\n",
      "12\t0.746\tThe Hermit of Eyton Forest\n",
      "12\t0.613\tThe Raven in the Foregate\n",
      "12\t0.592\tBoris Godunov\n",
      "12\t0.585\tYoung Sherlock Holmes: Black Ice\n",
      "12\t0.527\tDestined\n",
      "\n",
      "family father mother life wife daughter years husband brother time\n",
      "\n",
      "13\t0.971\tCoquette\n",
      "13\t0.955\tThe Mermaid Chair\n",
      "13\t0.941\tFire: From A Journal of Love\n",
      "13\t0.936\tBelinda\n",
      "13\t0.936\tThe Space Between Us\n",
      "\n",
      "book novel story world characters life character society describes author\n",
      "\n",
      "14\t0.971\tThe Master and His Emissary\n",
      "14\t0.967\tThe Democratic Paradox\n",
      "14\t0.950\tThe Globalized City\n",
      "14\t0.937\tIn the Line of Fire: A Memoir\n",
      "14\t0.921\tDemocracy and Education\n",
      "\n",
      "house tells find police room killed kill goes finds body\n",
      "\n",
      "15\t0.900\t\\\\\"V\\\\\" Is for Vengeance\n",
      "15\t0.887\tA Cool Head\n",
      "15\t0.823\tPhantom Lady\n",
      "15\t0.791\tNo Second Chance\n",
      "15\t0.768\tRum Punch\n",
      "\n",
      "stark ndash adams chancellor briar wall archer foundation animal darkness\n",
      "\n",
      "16\t0.929\tSoldier of Sidon\n",
      "16\t0.363\tButterfly\n",
      "16\t0.269\tA Useless Death\n",
      "16\t0.249\tMax the Mighty\n",
      "16\t0.230\tI Am Wings\n",
      "\n",
      "world god empire power time order fallen people priest end\n",
      "\n",
      "17\t0.886\tConqueror\n",
      "17\t0.802\tDarkest Mercy\n",
      "17\t0.739\tOn the Genealogy of Morals\n",
      "17\t0.735\tA Dissertation Concerning the End for Which God Created the World\n",
      "17\t0.718\tThe Simpsons: A Complete Guide to Our Favorite Family\n",
      "\n",
      "war general states army president united government forces military attack\n",
      "\n",
      "18\t0.846\tRed Alert\n",
      "18\t0.839\tRed Inferno: 1945\n",
      "18\t0.813\tArc Light\n",
      "18\t0.809\tThe Great War: Breakthroughs\n",
      "18\t0.802\tGrant Comes East\n",
      "\n",
      "ship crew captain mission aboard escape team island agent bond\n",
      "\n",
      "19\t0.772\tThe Family Arsenal\n",
      "19\t0.738\tLe repaire de la murène\n",
      "19\t0.737\tHammered\n",
      "19\t0.729\tAgainst All Enemies\n",
      "19\t0.713\tSaving the Queen\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_model=lda_model \n",
    "\n",
    "topic_docs=[]\n",
    "for i in range(num_topics):\n",
    "    topic_docs.append({})\n",
    "for doc_id in range(len(corpus)):\n",
    "    doc_topics=topic_model.get_document_topics(corpus[doc_id])\n",
    "    for topic_num, topic_prob in doc_topics:\n",
    "        topic_docs[topic_num][doc_id]=topic_prob\n",
    "\n",
    "for i in range(num_topics):\n",
    "    print(\"%s\\n\" % ' '.join([term for term, freq in topic_model.show_topic(i, topn=10)]))\n",
    "    sorted_x = sorted(topic_docs[i].items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for k, v in sorted_x[:5]:\n",
    "        print(\"%s\\t%.3f\\t%s\" % (i,v,doc_names[k]))\n",
    "    print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1f763f",
   "metadata": {},
   "source": [
    "Q: discuss the topics that emerge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f8d8f3",
   "metadata": {},
   "source": [
    "The no. 1 topic is the murder and detective stories. \\\n",
    "The no. 2 topic seems to be some fairy tales or children stories with animals as main characters. \\\n",
    "The no. 3 topic centers on human and society, but interestingly connects books from different genres like psychology and science fiction. \\\n",
    "The no. 4 topic is about family with various classes and cultural backgrounds. \\\n",
    "It is interesting that the tokens from book summaries can be connected to accurately categorize the books by topcis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6518833d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
